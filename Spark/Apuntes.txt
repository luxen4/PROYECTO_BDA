# docker-compose build  
# docker-compose up -d

# Problemas de espacio.
  wsl.exe --unregister docker-desktop-data

# liberación de espacio docker
# WSL --shutdown   



### Entrar al locastack ##
# docker exec -it b133839978b1e2c7dc49bcfa834087a6f9abd844f06b0912b60b223aad8cf29b /bin/bash    # casa
# docker exec -it spark-spark-master-1 /bin/bash

# docker exec -it a89c5d53234a8fac20dc932e1f4e53e48c2eb407d4f78825e711978143a4a0b1 /bin/bash    # clase

    # Crear un bucket por comando    ---> awslocal s3api create-bucket --bucket my-local-bucket
    # Listar los archivos del bucket ---> awslocal s3 ls s3://my-local-bucket
                                          ???  aws s3 ls s3://my-local-bucket/

# Ver el contenido de un bucket         ---> awslocal s3api list-objects --bucket my-local-bucket
# Eliminar un archivo de un bucket      ---> aws s3 rm s3://my-local-bucket/sales_data1.csv
# Listar los buckets                    ---> awslocal s3api list-buckets
# Eliminar el bucket                    ---> awslocal s3 rb s3://my-local-bucket --force

# Listar lo que hay debajo de la carpeta prueba    ---> awslocal s3 ls s3://my-local-bucket/prueba/


### Ver el contenido de un archivo virtual ###
    awslocal s3 cp s3://my-local-bucket/dataPokemon.json ./dataPokemon.json 
    cat dataPokemon.json   # En sistemas Unix-like
    type dataPokemon.json  # En Windows





# En docker
# ver el contenido de un csv de dentro de un bucket
# awslocal s3 cp s3://my-local-bucket/sales_data.csv -
# awslocal s3 cp s3://my-local-bucket/sales_data_procesado.csv/ -



###############
### Spark   ### contenedor spark-spark-master-1 #
###############
                                                                                                          
# cd '.\Tema 4\'
# cd .\Spark\
# docker exec -it spark-spark-master-1 /bin/bash   # casa  
# docker exec -it 0fe0b6f3a18314b1f9275fed8fe3235c71e01ba9391bbdb78773b8eeaa640a4a /bin/bash   # clase
# cd /opt/spark-apps     cd /opt/spark-data


#################
### Postgress ###
#################
# psql -U postgres
# create database primord_db;
# \c primord_db
# \l                                -> para ver las bases de datos
# \dt                               -> para ver las tablas
# DROP DATABASE mi_base_de_datos;
# \q o \quit
# DROP TABLE IF EXISTS stores;


#############
### MYSQL ###
#############
mysql -u root -p       alberite
show databases;
create database primord_db;
use primord_db;
drop table clientes;



############
Librerías
############
# pip3 install kafka-python==2.0.2
# python3 -m pip install numpy
# pip3 install --upgrade pandas==1.0.5
# python3 -m pip install pandas>=1.0.5
# pip3 install sqlalchemy
# pip3 install s3fs
# apt-get install libpq-dev
# pip3 install psycopg2
# python3 -m pip install psycopg2
# pip3 install py2neo
# pip install awscli-local

### MONGO ## pip3 show pymongo  pip3 install --upgrade pymongo




# aws configure
AWS Access Key ID [****************test]: test
AWS Secret Access Key [****************test]: test
Default region name [us-east-1]: us-east-1
Default output format [json]: json

# Configurar credenciales  ---> aws configure
# Resetear credenciales    ---> rm ~/.aws/config ~/.aws/credentials   
# Listar credenciales      ---> cat ~/.aws/credentials



# Para copiar archivos
docker cp C:/raul.png 103c83f8025d622b5fe5b812637aacf9b5fee1a20884cd34dd54bf9c14ec9b62:/opt/code/localstack/
Successfully copied 82.4kB to 90311ea633f9c9432dcdb4f63e39c8831bdbb4a130f4aa9394b29549358a4a30:/opt/code/localstack/

# Copiar archivos de C:/ a localstack
# docker cp C:/copiardelocastackabucket.txt 90311ea633f9c9432dcdb4f63e39c8831bdbb4a130f4aa9394b29549358a4a30:/opt/code/localstack/
# root@90311ea633f9:/opt/code/localstack# python fabricarcsv.py
# root@90311ea633f9:/opt/code/localstack# python procesar.py



Para guia de locastack
https://docs.localstack.cloud/user-guide/aws/s3/












https://www.youtube.com/watch?v=wHlaP8pr4uI




#############
### Neo4j ###
#############
Eliminar los registros ---> MATCH (n:Platos) DETACH DELETE n





# Leer un json
df = spark.read.json("./../../data_Prim_ord/json/restaurantes.json")
# Formas de leer https://www.diegocalvo.es/leer-y-escribir-json-en-python/






________________________________________________________________________________________________
git status                          # Verificar el estado del repositorio local
git add *                           # Añadir todos los cambios al área de preparación
git commit -m "Mensaje del commit"  # Hacer un commit de los cambios
git push                            # Realizar el push de los cambios a la rama principal del r

PS C:\Users\Adrian\Downloads\BDA_Adrian> git reset --soft HEAD~1
PS C:\Users\Adrian\Downloads\BDA_Adrian> git reset HEAD .
git rm --cached 'Tema 4/Spark/cont_Neo4j/transactions/neo4j/neostore.transaction.db.0'
git rm --cached 'Tema 4/Spark/cont_Neo4j/transactions/system/neostore.transaction.db.0'
________________________________________________________________________________________________




import sys
sys.path.append("..")
import sessions                    # Para importar archivos





















